import joblib
import numpy as np
import pandas as pd
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, r2_score
import warnings
import mlflow
import mlflow.sklearn

# D√©sactiver les avertissements
warnings.filterwarnings("ignore")

# Charger les donn√©es
dataset_path = "data/Consommation-de-carburant_data.csv"
if not os.path.exists(dataset_path):
    raise FileNotFoundError(f"Le fichier {dataset_path} n'existe pas. V√©rifiez le chemin.")

donnees = pd.read_csv(dataset_path, sep=",")

# Remplacer les '?' par NaN
donnees.replace('?', np.nan, inplace=True)

# Convertir les colonnes num√©riques
cols_numeric = ['mpg', 'weight', 'acceleration', 'displacement', 'cylinders', 'model year', 'horsepower']
for col in cols_numeric:
    donnees[col] = pd.to_numeric(donnees[col], errors='coerce')

# Gestion des valeurs manquantes
imputer = SimpleImputer(strategy='mean')
donnees[cols_numeric] = imputer.fit_transform(donnees[cols_numeric])

# Cr√©er la variable cible de r√©gression (mpg)
y_regression = donnees['mpg']  # Cible pour la r√©gression
X = donnees[['weight', 'acceleration', 'displacement', 'cylinders', 'model year', 'horsepower']]  # Variables pr√©dictives

# Standardisation des donn√©es
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# S√©paration des donn√©es en ensembles d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_regression, test_size=0.2, random_state=42)

# Entra√Ænement du mod√®le Random Forest Regressor
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)

# Pr√©dictions et √©valuation
y_pred = rf_reg.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Afficher les r√©sultats
print(f"Erreur quadratique moyenne pour Random Forest (r√©gression) : {mse:.4f}")
print(f"Coefficient de d√©termination R¬≤ pour Random Forest : {r2:.4f}")

# Cr√©ation du dossier de sauvegarde des mod√®les
models_dir = "models"
os.makedirs(models_dir, exist_ok=True)

# Sauvegarde des mod√®les avec joblib (optionnel si MLflow g√®re d√©j√† cela)
joblib.dump(rf_reg, os.path.join(models_dir, 'rf_reg_model.pkl'))
joblib.dump(scaler, os.path.join(models_dir, 'scaler.pkl'))


print("\nLe mod√®le a √©t√© sauvegard√© avec succ√®s.")

# 1Ô∏è‚É£ D√©finir l'URI de tracking (MLflow UI)
mlflow.set_tracking_uri("http://localhost:5000")

# 2Ô∏è‚É£ Cr√©er une exp√©rience
mlflow.set_experiment("Prediction_Consommation_Carburant")

# 3Ô∏è‚É£ D√©marrer un run
with mlflow.start_run():
    # Log des hyperparam√®tres (si besoin)
    mlflow.log_param("n_estimators", 100)  # Exemple pour RandomForest
    mlflow.log_param("max_depth", 10)

    # üéØ Log du mod√®le dans MLflow
    mlflow.sklearn.log_model(rf_reg, "rf_reg_model")
    mlflow.sklearn.log_model(scaler, "scaler_model")

    # üîπ Enregistrer les fichiers comme artefacts
    mlflow.log_artifact(os.path.join(models_dir, 'rf_reg_model.pkl'))
    mlflow.log_artifact(os.path.join(models_dir, 'scaler.pkl'))

    print("‚úÖ Mod√®les et artefacts enregistr√©s avec succ√®s dans MLflow ! üöÄ")


import mlflow.sklearn

# Charger le mod√®le RandomForest
rf_model = mlflow.sklearn.load_model("runs:/ba28e042d2634fb7adb13b83da0ff4c7/rf_reg_model")

# Charger le scaler
scaler_model = mlflow.sklearn.load_model("runs:/ba28e042d2634fb7adb13b83da0ff4c7/scaler_model")

print("‚úÖ Mod√®les charg√©s avec succ√®s !")
